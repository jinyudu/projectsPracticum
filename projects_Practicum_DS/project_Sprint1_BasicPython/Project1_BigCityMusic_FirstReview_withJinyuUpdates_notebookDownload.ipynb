{"cells":[{"cell_type":"markdown","metadata":{},"source":"<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n<b> Reviewer's comment</b>\n    \nHello, my name is Sveta Nosova and I am going to review this project. \n\nBefore we start, I want to pay your attention to the color marking:\n    \n<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<b> Reviewer's comment</b>\n    \nGreat solutions and ideas that can and should be used in the future are in green comments.   \n</div>    \n    \n    \n<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<b> Reviewer's comment</b>\n\nYellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project.\n</div>      \n    \n    \n<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<b> Reviewer's comment</b>\n\nIssues that need to be corrected to get right results are indicated in red comments. Note that the project cannot be accepted until these issues are resolved.\n</div>    \n\n<hr>\n    \n**Please, use some color other than those listed to highlight answers to my comments.**\nI would also ask you **not to change, move or delete my comments** so that it would be easier for me to navigate during the next review.\n    \nIn addition, my comments are defined as headings. \nThey can mess up the content, however, they are convenient, since you can immediately go to them. I will remove the headings from my comments in the next review. \n   \n    \n    \n<hr>\n    \n<font color='dodgerblue'>**A few words about the project:**</font> you did a great job, everything is clear and neat. I've left a couple of recommendations for improving the project. I have no questions and there are no issues that need to be fixed, so I can accept the project now. However, I will send it back to you so that you have the opportunity to ask me questions, if you have any.\n    \n\n    \n    \nHere are some hints that may help you with Markdown cells:    \n<hr style=\"border-top: 3px solid purple; \"></hr>\n\nYou can leave comments using this code inside a Markdown cell:\n    \n    \n    <div class=\"alert alert-info\">\n    <h2> Student's comment</h2>\n\n    Your text here. \n    </div>\n\n    \n    \n    <font color='red'> This code is used to change text color. </font>     \n\n<font color='red'> It will look like this. </font> \n    \nIf you don't want your comments to be headings, replace **h2** with **b** or just add `<a class=\"tocSkip\">` after the phrase *Student's comment*.\n\n\nYou can find out how to **format text** in a Markdown cell or how to **add links** [here](https://sqlbak.com/blog/jupyter-notebook-markdown-cheatsheet) и [and here](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd).\n\n\n\n</div>\n"},{"cell_type":"markdown","metadata":{"id":"E0vqbgi9ay0H"},"source":"# Yandex.Music"},{"cell_type":"markdown","metadata":{"id":"fhq_eyov_Zcs"},"source":"# Contents <a id='back'></a>\n\n* [Introduction](#intro)\n* [Stage 1. Data overview](#data_review)\n    * [Conclusions](#data_review_conclusions)\n* [Stage 2. Data preprocessing](#data_preprocessing)\n    * [2.1 Header style](#header_style)\n    * [2.2 Missing values](#missing_values)\n    * [2.3 Duplicates](#duplicates)\n    * [2.4 Conclusions](#data_preprocessing_conclusions)\n* [Stage 3. Testing the hypotheses](#hypotheses)\n    * [3.1 Hypothesis 1: user activity in the two cities](#activity)\n    * [3.2 Hypothesis 2: music preferences on Monday and Friday](#week)\n    * [3.3 Hypothesis 3: genre preferences in Springfield and Shelbyville](#genre)\n* [Findings](#end)"},{"cell_type":"markdown","metadata":{"id":"VUC88oWjTJw2"},"source":"## Introduction <a id='intro'></a>\nWhenever we're doing research, we need to formulate hypotheses that we can then test. Sometimes we accept these hypotheses; other times, we reject them. To make the right decisions, a business must be able to understand whether or not it's making the right assumptions.\n\nIn this project, you'll compare the music preferences of the cities of Springfield and Shelbyville. You'll study real Yandex.Music data to test the hypotheses below and compare user behavior for these two cities.\n\n### Goal: \nTest three hypotheses:\n1. User activity differs depending on the day of the week and from city to city. \n2. On Monday mornings, Springfield and Shelbyville residents listen to different genres. This is also true for Friday evenings. \n3. Springfield and Shelbyville listeners have different preferences. In Springfield, they prefer pop, while Shelbyville has more rap fans.\n\n### Stages \nData on user behavior is stored in the file `/datasets/music_project_en.csv`. There is no information about the quality of the data, so you will need to explore it before testing the hypotheses. \n\nFirst, you'll evaluate the quality of the data and see whether its issues are significant. Then, during data preprocessing, you will try to account for the most critical problems.\n \nYour project will consist of three stages:\n 1. Data overview\n 2. Data preprocessing\n 3. Testing the hypotheses\n \n[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nThere's an introduction, which is good. It is important to write an introductory part, because it gives an idea about the content of the project.\n</div>"},{"cell_type":"markdown","metadata":{"id":"Ml1hmfXC_Zcs"},"source":"## Stage 1. Data overview <a id='data_review'></a>\n\nOpen the data on Yandex.Music and explore it."},{"cell_type":"markdown","metadata":{"id":"57eAOGIz_Zcs"},"source":"You'll need `pandas`, so import it."},{"cell_type":"code","execution_count":1,"metadata":{"id":"AXN7PHPN_Zcs","trusted":true},"outputs":[],"source":"import pandas as pd\ndf = pd.read_csv('/datasets/music_project_en.csv')"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nGood thing you are using **pd** to reference pandas. It is convenient as every programmer or analyst has to look for the information on the web or in a documentation. Sometimes you may search for a ready solution and use of a common style is a good idea here as it simplifies understanding someone's code and even copy-paste process. \n     \n</div>"},{"cell_type":"markdown","metadata":{"id":"SG23P8tt_Zcs"},"source":"Read the file `music_project_en.csv` from the `/datasets/` folder and save it in the `df` variable:"},{"cell_type":"code","execution_count":2,"metadata":{"id":"fFVu7vqh_Zct","trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>Track</th>\n      <th>artist</th>\n      <th>genre</th>\n      <th>City</th>\n      <th>time</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>65079</td>\n      <td>63736</td>\n      <td>57512</td>\n      <td>63881</td>\n      <td>65079</td>\n      <td>65079</td>\n      <td>65079</td>\n    </tr>\n    <tr>\n      <td>unique</td>\n      <td>41748</td>\n      <td>39666</td>\n      <td>37806</td>\n      <td>268</td>\n      <td>2</td>\n      <td>20392</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>top</td>\n      <td>A8AE9169</td>\n      <td>Brand</td>\n      <td>Kartvelli</td>\n      <td>pop</td>\n      <td>Springfield</td>\n      <td>08:14:07</td>\n      <td>Friday</td>\n    </tr>\n    <tr>\n      <td>freq</td>\n      <td>76</td>\n      <td>136</td>\n      <td>136</td>\n      <td>8850</td>\n      <td>45360</td>\n      <td>14</td>\n      <td>23149</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          userID  Track     artist  genre       City        time     Day\ncount      65079  63736      57512  63881        65079     65079   65079\nunique     41748  39666      37806    268            2     20392       3\ntop     A8AE9169  Brand  Kartvelli    pop  Springfield  08:14:07  Friday\nfreq          76    136        136   8850        45360        14   23149"},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":"# reading the file and storing it to df\ndf.describe()"},{"cell_type":"markdown","metadata":{"id":"rDoOMd3uTqnZ"},"source":"Print the first 10 table rows:"},{"cell_type":"code","execution_count":3,"metadata":{"id":"oWTVX3gW_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}],"source":"# obtaining the first 10 rows from the df table\nprint(df.head(10))"},{"cell_type":"markdown","metadata":{"id":"EO73Kwic_Zct"},"source":"Obtaining the general information about the table with one command:"},{"cell_type":"code","execution_count":4,"metadata":{"id":"DSf2kIb-_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n  userID    65079 non-null object\nTrack       63736 non-null object\nartist      57512 non-null object\ngenre       63881 non-null object\n  City      65079 non-null object\ntime        65079 non-null object\nDay         65079 non-null object\ndtypes: object(7)\nmemory usage: 3.5+ MB\n"}],"source":"# obtaining general information about the data in df\ndf.info()"},{"cell_type":"markdown","metadata":{"id":"TaQ2Iwbr_Zct"},"source":"The table contains seven columns. They all store the same data type: `object`.\n\nAccording to the documentation:\n- `'userID'` — user identifier\n- `'Track'` — track title\n- `'artist'` — artist's name\n- `'genre'`\n- `'City'` — user's city\n- `'time'` — the exact time the track was played\n- `'Day'` — day of the week\n\nWe can see three issues with style in the column names:\n1. Some names are uppercase, some are lowercase.\n2. There are spaces in some names.\n3. The name `userID` has two words and it did not use snake_case.\n\nThe number of column values is different. This means the data contains missing values.\n"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nIndeed. It also saves our time when we work with somebody's code.     \n\n</div>"},{"cell_type":"markdown","metadata":{"id":"MCB6-dXG_Zct"},"source":"### Conclusions <a id='data_review_conclusions'></a> \n\nEach row in the table stores data on a track that was played. Some columns describe the track itself: its title, artist and genre. The rest convey information about the user: the city they come from, the time they played the track. \n\nIt's clear that the data is sufficient to test the hypotheses. However, there are missing values.\n\nTo move forward, we need to preprocess the data."},{"cell_type":"markdown","metadata":{"id":"3eL__vcwViOi"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"SjYF6Ub9_Zct"},"source":"## Stage 2. Data preprocessing <a id='data_preprocessing'></a>\nCorrect the formatting in the column headers and deal with the missing values. Then, check whether there are duplicates in the data."},{"cell_type":"markdown","metadata":{"id":"dIaKXr29_Zct"},"source":"### Header style <a id='header_style'></a>\nPrint the column header:"},{"cell_type":"code","execution_count":5,"metadata":{"id":"oKOTdF_Q_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}],"source":"print(df.columns)"},{"cell_type":"markdown","metadata":{"id":"zj5534cv_Zct"},"source":"Change column names according to the rules of good style:\n* If the name has several words, use snake_case\n* All characters must be lowercase\n* Delete spaces"},{"cell_type":"code","execution_count":6,"metadata":{"id":"ISlFqs5y_Zct","trusted":true},"outputs":[],"source":"# renaming columns\ndf = df.rename(\n    columns = {\n        '  userID':'user_id', \n        'Track':'track',\n        '  City  ':'city', \n        'Day':'day',\n    }\n)"},{"cell_type":"markdown","metadata":{"id":"1dqbh00J_Zct"},"source":"Check the result. Print the names of the columns once more:"},{"cell_type":"code","execution_count":7,"metadata":{"id":"d4NOAmTW_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}],"source":"# checking result: the list of column names\nprint(df.columns)"},{"cell_type":"markdown","metadata":{"id":"xYJk6ksJVpOl"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"5ISfbcfY_Zct"},"source":"### Missing values <a id='missing_values'></a>\nFirst, find the number of missing values in the table. To do so, use two `pandas` methods:"},{"cell_type":"code","execution_count":8,"metadata":{"id":"RskX29qr_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"user_id       0\ntrack      1343\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\nuser_id       0\ntrack      1343\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\n"}],"source":"# calculating missing values\n\n# the first `pandas` method to check the number of missing values in the table:\nprint(df.isna().sum())\n\n# the second `pandas` method to check the number of missing values in the table:\nprint(df.isnull().sum())"},{"cell_type":"markdown","metadata":{"id":"qubhgnlO_Zct"},"source":"Not all missing values affect the research. For instance, the missing values in `track` and `artist` are not critical. You can simply replace them with clear markers.\n\nBut missing values in `'genre'` can affect the comparison of music preferences in Springfield and Shelbyville. In real life, it would be useful to learn the reasons why the data is missing and try to make up for them. But we do not have that opportunity in this project. So you will have to:\n* Fill in these missing values with markers\n* Evaluate how much the missing values may affect your computations"},{"cell_type":"markdown","metadata":{"id":"fSv2laPA_Zct"},"source":"Replace the missing values in `'track'`, `'artist'`, and `'genre'` with the string `'unknown'`. To do this, create the `columns_to_replace` list, loop over it with `for`, and replace the missing values in each of the columns:"},{"cell_type":"code","execution_count":9,"metadata":{"id":"KplB5qWs_Zct","trusted":true},"outputs":[],"source":"# looping over column names and replacing missing values with 'unknown'\n\ncolumns_to_replace = ['track', 'artist', 'genre']\n\nfor column in columns_to_replace:\n    df[column] = df[column].fillna('unknown')\n"},{"cell_type":"markdown","metadata":{"id":"Ilsm-MZo_Zct"},"source":"Make sure the table contains no more missing values. Count the missing values again."},{"cell_type":"code","execution_count":10,"metadata":{"id":"Tq4nYRX4_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"user_id    0\ntrack      0\nartist     0\ngenre      0\ncity       0\ntime       0\nday        0\ndtype: int64\n"}],"source":"# counting missing values\nprint(df.isna().sum())"},{"cell_type":"markdown","metadata":{"id":"74ZIBmq9VrsK"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"BWKRtBJ3_Zct"},"source":"### Duplicates <a id='duplicates'></a>\nFind the number of obvious duplicates in the table using one command:"},{"cell_type":"code","execution_count":11,"metadata":{"id":"36eES_S0_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3826\n"}],"source":"# counting clear duplicates\nprint(df.duplicated().sum())"},{"cell_type":"markdown","metadata":{"id":"Ot25h6XR_Zct"},"source":"Call the `pandas` method for getting rid of obvious duplicates:"},{"cell_type":"code","execution_count":12,"metadata":{"id":"exFHq6tt_Zct","trusted":true},"outputs":[],"source":"# removing obvious duplicates\ndf = df.drop_duplicates().reset_index(drop=True)"},{"cell_type":"markdown","metadata":{"id":"Im2YwBEG_Zct"},"source":"Count obvious duplicates once more to make sure you have removed all of them:"},{"cell_type":"code","execution_count":13,"metadata":{"id":"-8PuNWQ0_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0\n"}],"source":"# checking for duplicates\nprint(df.duplicated().sum())"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nNo more duplicates, good :)\n</div>"},{"cell_type":"markdown","metadata":{"id":"QlFBsxAr_Zct"},"source":"Now get rid of implicit duplicates in the `genre` column. For example, the name of a genre can be written in different ways. Such errors will also affect the result."},{"cell_type":"markdown","metadata":{"id":"eSjWwsOh_Zct"},"source":"Print a list of unique genre names, sorted in alphabetical order. To do so:\n* Retrieve the intended DataFrame column \n* Apply a sorting method to it\n* For the sorted column, call the method that will return all unique column values"},{"cell_type":"code","execution_count":14,"metadata":{"id":"JIUcqzZN_Zct","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"['acid' 'acoustic' 'action' 'adult' 'africa' 'afrikaans' 'alternative'\n 'ambient' 'americana' 'animated' 'anime' 'arabesk' 'arabic' 'arena'\n 'argentinetango' 'art' 'audiobook' 'avantgarde' 'axé' 'baile' 'balkan'\n 'beats' 'bigroom' 'black' 'bluegrass' 'blues' 'bollywood' 'bossa'\n 'brazilian' 'breakbeat' 'breaks' 'broadway' 'cantautori' 'cantopop'\n 'canzone' 'caribbean' 'caucasian' 'celtic' 'chamber' 'children' 'chill'\n 'chinese' 'choral' 'christian' 'christmas' 'classical' 'classicmetal'\n 'club' 'colombian' 'comedy' 'conjazz' 'contemporary' 'country' 'cuban'\n 'dance' 'dancehall' 'dancepop' 'dark' 'death' 'deep' 'deutschrock'\n 'deutschspr' 'dirty' 'disco' 'dnb' 'documentary' 'downbeat' 'downtempo'\n 'drum' 'dub' 'dubstep' 'eastern' 'easy' 'electronic' 'electropop' 'emo'\n 'entehno' 'epicmetal' 'estrada' 'ethnic' 'eurofolk' 'european'\n 'experimental' 'extrememetal' 'fado' 'film' 'fitness' 'flamenco' 'folk'\n 'folklore' 'folkmetal' 'folkrock' 'folktronica' 'forró' 'frankreich'\n 'französisch' 'french' 'funk' 'future' 'gangsta' 'garage' 'german'\n 'ghazal' 'gitarre' 'glitch' 'gospel' 'gothic' 'grime' 'grunge' 'gypsy'\n 'handsup' \"hard'n'heavy\" 'hardcore' 'hardstyle' 'hardtechno' 'hip'\n 'hip-hop' 'hiphop' 'historisch' 'holiday' 'hop' 'horror' 'house' 'idm'\n 'independent' 'indian' 'indie' 'indipop' 'industrial' 'inspirational'\n 'instrumental' 'international' 'irish' 'jam' 'japanese' 'jazz' 'jewish'\n 'jpop' 'jungle' 'k-pop' 'karadeniz' 'karaoke' 'kayokyoku' 'korean'\n 'laiko' 'latin' 'latino' 'leftfield' 'local' 'lounge' 'loungeelectronic'\n 'lovers' 'malaysian' 'mandopop' 'marschmusik' 'meditative'\n 'mediterranean' 'melodic' 'metal' 'metalcore' 'mexican' 'middle'\n 'minimal' 'miscellaneous' 'modern' 'mood' 'mpb' 'muslim' 'native'\n 'neoklassik' 'neue' 'new' 'newage' 'newwave' 'nu' 'nujazz' 'numetal'\n 'oceania' 'old' 'opera' 'orchestral' 'other' 'piano' 'pop'\n 'popelectronic' 'popeurodance' 'post' 'posthardcore' 'postrock' 'power'\n 'progmetal' 'progressive' 'psychedelic' 'punjabi' 'punk' 'quebecois'\n 'ragga' 'ram' 'rancheras' 'rap' 'rave' 'reggae' 'reggaeton' 'regional'\n 'relax' 'religious' 'retro' 'rhythm' 'rnb' 'rnr' 'rock' 'rockabilly'\n 'romance' 'roots' 'ruspop' 'rusrap' 'rusrock' 'salsa' 'samba' 'schlager'\n 'self' 'sertanejo' 'shoegazing' 'showtunes' 'singer' 'ska' 'slow'\n 'smooth' 'soul' 'soulful' 'sound' 'soundtrack' 'southern' 'specialty'\n 'speech' 'spiritual' 'sport' 'stonerrock' 'surf' 'swing' 'synthpop'\n 'sängerportrait' 'tango' 'tanzorchester' 'taraftar' 'tech' 'techno'\n 'thrash' 'top' 'traditional' 'tradjazz' 'trance' 'tribal' 'trip'\n 'triphop' 'tropical' 'türk' 'türkçe' 'unknown' 'urban' 'uzbek' 'variété'\n 'vi' 'videogame' 'vocal' 'western' 'world' 'worldbeat' 'ïîï']\n"}],"source":"# viewing unique genre names\nprint(df.sort_values(by = 'genre')['genre'].unique())"},{"cell_type":"markdown","metadata":{"id":"qej-Qmuo_Zct"},"source":"Look through the list to find implicit duplicates of the genre `hiphop`. These could be names written incorrectly or alternative names of the same genre.\n\nYou will see the following implicit duplicates:\n* `hip`\n* `hop`\n* `hip-hop`\n\nTo get rid of them, declare the function `replace_wrong_genres()` with two parameters: \n* `wrong_genres=` — the list of duplicates\n* `correct_genre=` — the string with the correct value\n\nThe function should correct the names in the `'genre'` column from the `df` table, i.e. replace each value from the `wrong_genres` list with the value in `correct_genre`."},{"cell_type":"code","execution_count":15,"metadata":{"id":"ErNDkmns_Zct","trusted":true},"outputs":[],"source":"# function for replacing implicit duplicates\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for wrong_genre in wrong_genres:\n        df['genre'] = df['genre'].replace(wrong_genre, correct_genre)\n    "},{"cell_type":"markdown","metadata":{"id":"aDoBJxbA_Zct"},"source":"Call `replace_wrong_genres()` and pass it arguments so that it clears implicit duplcates (`hip`, `hop`, and `hip-hop`) and replaces them with `hiphop`:"},{"cell_type":"code","execution_count":16,"metadata":{"id":"YN5i2hpmSo09","trusted":true},"outputs":[],"source":"# removing implicit duplicates\nduplicates = ['hip', 'hop', 'hip-hop']\ncorrect_genre_name = 'hiphop'\n\nreplace_wrong_genres(duplicates, correct_genre_name)"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nCool 😊 We wrote and called a function that worked correctly.\n\nIn general, these manipulations can be performed without a function. To do this, we need a list and the same **replace** method. It will look like this:\n    \n    \n    wrong_genres = ['hip', 'hop', 'hip-hop']\n    correct_genre = 'hiphop'  \n\n    df['genre'] = df['genre'].replace(wrong_genres, correct_genre)\n    \n    \nOr, which is the same:\n    \n    \n    df['genre'] = df['genre'].replace(['hip', 'hop', 'hip-hop'], 'hiphop')\n</div>"},{"cell_type":"markdown","metadata":{"id":"zQKF16_RG15m"},"source":"Make sure the duplicate names were removed. Print the list of unique values from the `'genre'` column:"},{"cell_type":"code","execution_count":17,"metadata":{"id":"wvixALnFG15m","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"['acid' 'acoustic' 'action' 'adult' 'africa' 'afrikaans' 'alternative'\n 'ambient' 'americana' 'animated' 'anime' 'arabesk' 'arabic' 'arena'\n 'argentinetango' 'art' 'audiobook' 'avantgarde' 'axé' 'baile' 'balkan'\n 'beats' 'bigroom' 'black' 'bluegrass' 'blues' 'bollywood' 'bossa'\n 'brazilian' 'breakbeat' 'breaks' 'broadway' 'cantautori' 'cantopop'\n 'canzone' 'caribbean' 'caucasian' 'celtic' 'chamber' 'children' 'chill'\n 'chinese' 'choral' 'christian' 'christmas' 'classical' 'classicmetal'\n 'club' 'colombian' 'comedy' 'conjazz' 'contemporary' 'country' 'cuban'\n 'dance' 'dancehall' 'dancepop' 'dark' 'death' 'deep' 'deutschrock'\n 'deutschspr' 'dirty' 'disco' 'dnb' 'documentary' 'downbeat' 'downtempo'\n 'drum' 'dub' 'dubstep' 'eastern' 'easy' 'electronic' 'electropop' 'emo'\n 'entehno' 'epicmetal' 'estrada' 'ethnic' 'eurofolk' 'european'\n 'experimental' 'extrememetal' 'fado' 'film' 'fitness' 'flamenco' 'folk'\n 'folklore' 'folkmetal' 'folkrock' 'folktronica' 'forró' 'frankreich'\n 'französisch' 'french' 'funk' 'future' 'gangsta' 'garage' 'german'\n 'ghazal' 'gitarre' 'glitch' 'gospel' 'gothic' 'grime' 'grunge' 'gypsy'\n 'handsup' \"hard'n'heavy\" 'hardcore' 'hardstyle' 'hardtechno' 'hiphop'\n 'historisch' 'holiday' 'horror' 'house' 'idm' 'independent' 'indian'\n 'indie' 'indipop' 'industrial' 'inspirational' 'instrumental'\n 'international' 'irish' 'jam' 'japanese' 'jazz' 'jewish' 'jpop' 'jungle'\n 'k-pop' 'karadeniz' 'karaoke' 'kayokyoku' 'korean' 'laiko' 'latin'\n 'latino' 'leftfield' 'local' 'lounge' 'loungeelectronic' 'lovers'\n 'malaysian' 'mandopop' 'marschmusik' 'meditative' 'mediterranean'\n 'melodic' 'metal' 'metalcore' 'mexican' 'middle' 'minimal'\n 'miscellaneous' 'modern' 'mood' 'mpb' 'muslim' 'native' 'neoklassik'\n 'neue' 'new' 'newage' 'newwave' 'nu' 'nujazz' 'numetal' 'oceania' 'old'\n 'opera' 'orchestral' 'other' 'piano' 'pop' 'popelectronic' 'popeurodance'\n 'post' 'posthardcore' 'postrock' 'power' 'progmetal' 'progressive'\n 'psychedelic' 'punjabi' 'punk' 'quebecois' 'ragga' 'ram' 'rancheras'\n 'rap' 'rave' 'reggae' 'reggaeton' 'regional' 'relax' 'religious' 'retro'\n 'rhythm' 'rnb' 'rnr' 'rock' 'rockabilly' 'romance' 'roots' 'ruspop'\n 'rusrap' 'rusrock' 'salsa' 'samba' 'schlager' 'self' 'sertanejo'\n 'shoegazing' 'showtunes' 'singer' 'ska' 'slow' 'smooth' 'soul' 'soulful'\n 'sound' 'soundtrack' 'southern' 'specialty' 'speech' 'spiritual' 'sport'\n 'stonerrock' 'surf' 'swing' 'synthpop' 'sängerportrait' 'tango'\n 'tanzorchester' 'taraftar' 'tech' 'techno' 'thrash' 'top' 'traditional'\n 'tradjazz' 'trance' 'tribal' 'trip' 'triphop' 'tropical' 'türk' 'türkçe'\n 'unknown' 'urban' 'uzbek' 'variété' 'vi' 'videogame' 'vocal' 'western'\n 'world' 'worldbeat' 'ïîï']\n"}],"source":"# checking for implicit duplicates\nprint(df.sort_values(by = 'genre')['genre'].unique())"},{"cell_type":"markdown","metadata":{"id":"ALgNbvF3VtPA"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"jz6a9-7HQUDd"},"source":"### Conclusions <a id='data_preprocessing_conclusions'></a>\nWe detected three issues with the data:\n\n- Incorrect header styles\n- Missing values\n- Obvious and implicit duplicates\n\nThe headers have been cleaned up to make processing the table simpler.\n\nAll missing values have been replaced with `'unknown'`. But we still have to see whether the missing values in `'genre'` will affect our calculations.\n\nThe absence of duplicates will make the results more precise and easier to understand.\n\nNow we can move on to testing hypotheses. "},{"cell_type":"markdown","metadata":{"id":"eK1es74rVujj"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"WttZHXH0SqKk"},"source":"## Stage 3. Testing hypotheses <a id='hypotheses'></a>"},{"cell_type":"markdown","metadata":{"id":"Im936VVi_Zcu"},"source":"### Hypothesis 1: comparing user behavior in two cities <a id='activity'></a>"},{"cell_type":"markdown","metadata":{"id":"nwt_MuaL_Zcu"},"source":"According to the first hypothesis, users from Springfield and Shelbyville listen to music differently. Test this using the data on three days of the week: Monday, Wednesday, and Friday.\n\n* Divide the users into groups by city.\n* Compare how many tracks each group played on Monday, Wednesday, and Friday.\n"},{"cell_type":"markdown","metadata":{"id":"8Dw_YMmT_Zcu"},"source":"For the sake of practice, perform each computation separately. \n\nEvaluate user activity in each city. Group the data by city and find the number of songs played in each group.\n\n"},{"cell_type":"code","execution_count":18,"metadata":{"id":"0_Qs96oh_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"             user_id  track  artist  genre   time    day\ncity                                                    \nShelbyville    18512  18512   18512  18512  18512  18512\nSpringfield    42741  42741   42741  42741  42741  42741\n"}],"source":"# Counting up the tracks played in each city\nprint(df.groupby('city').count())"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \n\nAs you can see, the numbers are the same in all columns. This is because the **count** method has the same logic: to  count the number of rows. So you can just take one column:\n\n</div>"},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":"city\nShelbyville    18512\nSpringfield    42741\nName: user_id, dtype: int64"},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":"# Reviewer's code\ndf.groupby('city')['user_id'].count()"},{"cell_type":"markdown","metadata":{"id":"dzli3w8o_Zcu"},"source":"Springfield has more tracks played than Shelbyville. But that does not imply that citizens of Springfield listen to music more often. This city is simply bigger, and there are more users.\n\nNow group the data by day of the week and find the number of tracks played on Monday, Wednesday, and Friday.\n"},{"cell_type":"code","execution_count":19,"metadata":{"id":"uZMKjiJz_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"           user_id  track  artist  genre   city   time\nday                                                   \nFriday       21840  21840   21840  21840  21840  21840\nMonday       21354  21354   21354  21354  21354  21354\nWednesday    18059  18059   18059  18059  18059  18059\n"}],"source":"# Calculating tracks played on each of the three days\nprint(df.groupby('day').count())"},{"cell_type":"markdown","metadata":{},"source":"\n<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nHere we can take one column here too. By the way, if you do not like the output with Series, as it was done in my previous code, you can print the result as a table by adding more parentheses:\n\n</div>"},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n    </tr>\n    <tr>\n      <th>day</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Friday</td>\n      <td>21840</td>\n    </tr>\n    <tr>\n      <td>Monday</td>\n      <td>21354</td>\n    </tr>\n    <tr>\n      <td>Wednesday</td>\n      <td>18059</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"           user_id\nday               \nFriday       21840\nMonday       21354\nWednesday    18059"},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":"# Reviewer's code\n\ndf.groupby('day')[['user_id']].count()"},{"cell_type":"markdown","metadata":{"id":"cC2tNrlL_Zcu"},"source":"Wednesday is the quietest day overall. But if we consider the two cities separately, we might come to a different conclusion."},{"cell_type":"markdown","metadata":{"id":"POzs8bGa_Zcu"},"source":"You have seen how grouping by city or day works. Now write a function that will group by both.\n\nCreate the `number_tracks()` function to calculate the number of songs played for a given day and city. It will require two parameters:\n* day of the week\n* name of the city\n\nIn the function, use a variable to store the rows from the original table, where:\n  * `'day'` column value is equal to the `day` parameter\n  * `'city'` column value is equal to the `city` parameter\n\nApply consecutive filtering with logical indexing.\n\nThen calculate the `'user_id'` column values in the resulting table. Store the result to a new variable. Return this variable from the function."},{"cell_type":"code","execution_count":20,"metadata":{"id":"Nz3GdQB1_Zcu","trusted":true},"outputs":[],"source":"# <creating the function number_tracks()>\n# We'll declare a function with two parameters: day=, city=.\n# Let the track_list variable store the df rows where\n# the value in the 'day' column is equal to the day= parameter and, at the same time, \n# the value in the 'city' column is equal to the city= parameter (apply consecutive filtering \n# with logical indexing).\n# Let the track_list_count variable store the number of 'user_id' column values in track_list\n# (found with the count() method).\n# Let the function return a number: the value of track_list_count.\n\n# The function counts tracked played for a certain city and day.\n# It first retrieves the rows with the intended day from the table,\n# then filters out the rows with the intended city from the result,\n# then finds the number of 'user_id' values in the filtered table,\n# then returns that number.\n# To see what it returns, wrap the function call in print().\n\ndef number_tracks(day, city):\n    track_list = df[(df['day']==day) & (df['city']==city)]\n    track_list_count = track_list['user_id'].count()\n    return track_list_count"},{"cell_type":"markdown","metadata":{"id":"ytf7xFrFJQ2r"},"source":"Call `number_tracks()` six times, changing the parameter values, so that you retrieve the data on both cities for each of the three days."},{"cell_type":"code","execution_count":21,"metadata":{"id":"rJcRATNQ_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"15740\n"}],"source":"# the number of songs played in Springfield on Monday\nspring_mon = number_tracks('Monday', 'Springfield')\nprint(spring_mon)"},{"cell_type":"code","execution_count":22,"metadata":{"id":"hq_ncZ5T_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"5614\n"}],"source":"# the number of songs played in Shelbyville on Monday\nshelby_mon = number_tracks('Monday', 'Shelbyville')\nprint(shelby_mon)"},{"cell_type":"code","execution_count":23,"metadata":{"id":"_NTy2VPU_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"11056\n"}],"source":"# the number of songs played in Springfield on Wednesday\nspring_wed = number_tracks('Wednesday', 'Springfield')\nprint(spring_wed)"},{"cell_type":"code","execution_count":24,"metadata":{"id":"j2y3TAwo_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"7003\n"}],"source":"# the number of songs played in Shelbyville on Wednesday\nshelby_wed = number_tracks('Wednesday', 'Shelbyville')\nprint(shelby_wed)"},{"cell_type":"code","execution_count":25,"metadata":{"id":"vYDw5u_K_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"15945\n"}],"source":"# the number of songs played in Springfield on Friday\nspring_fri = number_tracks('Friday', 'Springfield')\nprint(spring_fri)"},{"cell_type":"code","execution_count":26,"metadata":{"id":"8_yzFtW3_Zcu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"5895\n"}],"source":"# the number of songs played in Shelbyville on Friday\nshelby_fri = number_tracks('Friday', 'Shelbyville')\nprint(shelby_fri)"},{"cell_type":"markdown","metadata":{"id":"7QXffbO-_Zcu"},"source":"Use `pd.DataFrame` to create a table, where\n* Column names are: `['city', 'monday', 'wednesday', 'friday']`\n* The data is the results you got from `number_tracks()`"},{"cell_type":"code","execution_count":27,"metadata":{"id":"APAcLpOr_Zcu","trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>monday</th>\n      <th>wednesday</th>\n      <th>friday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Springfield</td>\n      <td>15740</td>\n      <td>11056</td>\n      <td>15945</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Shelbyville</td>\n      <td>5614</td>\n      <td>7003</td>\n      <td>5895</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          city  monday  wednesday  friday\n0  Springfield   15740      11056   15945\n1  Shelbyville    5614       7003    5895"},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":"# table with results\ncol_names = ['city', 'monday', 'wednesday', 'friday']\ncount_data = [\n    ['Springfield', spring_mon, spring_wed, spring_fri],\n    ['Shelbyville', shelby_mon, shelby_wed, shelby_fri]   \n]\n\npd.DataFrame(data=count_data, columns=col_names)"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nAll values are correct.</div>"},{"cell_type":"markdown","metadata":{"id":"-EgPIHYu_Zcu"},"source":"**Conclusions**\n\nThe data reveals differences in user behavior:\n\n- In Springfield, the number of songs played peaks on Mondays and Fridays, while on Wednesday there is a decrease in activity.\n- In Shelbyville, on the contrary, users listen to music more on Wednesday. User activity on Monday and Friday is smaller.\n\nSo the first hypothesis seems to be correct."},{"cell_type":"markdown","metadata":{"id":"p7nFQajCVw5B"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"atZAxtq4_Zcu"},"source":"### Hypothesis 2: music at the beginning and end of the week <a id='week'></a>"},{"cell_type":"markdown","metadata":{"id":"eXrQqXFH_Zcu"},"source":"According to the second hypothesis, on Monday morning and Friday night, citizens of Springfield listen to genres that differ from ones users from Shelbyville enjoy."},{"cell_type":"markdown","metadata":{"id":"S8UcW6Hw_Zcu"},"source":"Get tables (make sure that the name of your combined table matches the DataFrame given in the two code blocks below):\n* For Springfield — `spr_general`\n* For Shelbyville — `shel_general`"},{"cell_type":"code","execution_count":28,"metadata":{"id":"qeaFfM_P_Zcu","trusted":true},"outputs":[],"source":"# obtaining the spr_general table from the df rows, \n# where the value in the 'city' column is 'Springfield'\n\nspr_general = df[df['city'] == 'Springfield']"},{"cell_type":"code","execution_count":29,"metadata":{"id":"ORaVRKto_Zcu","trusted":true},"outputs":[],"source":"# obtaining the shel_general from the df rows,\n# where the value in the 'city' column is 'Shelbyville'\n\nshel_general = df[df['city'] == 'Shelbyville']"},{"cell_type":"markdown","metadata":{"id":"MEJV-CX2_Zcu"},"source":"Write the `genre_weekday()` function with four parameters:\n* A table for data\n* The day of the week\n* The first timestamp, in 'hh:mm' format\n* The last timestamp, in 'hh:mm' format\n\nThe function should return info on the 15 most popular genres on a given day within the period between the two timestamps."},{"cell_type":"code","execution_count":30,"metadata":{"id":"laJT9BYl_Zcu","trusted":true},"outputs":[],"source":"# Declaring the genre_weekday() function with the parameters day=, time1=, and time2=. It should\n# return information about the most popular genres on a given day at a given time:\n\n# 1) Let the genre_df variable store the rows that meet several conditions:\n#    - the value in the 'day' column is equal to the value of the day= argument\n#    - the value in the 'time' column is greater than the value of the time1= argument\n#    - the value in the 'time' column is smaller than the value of the time2= argument\n#    Use consecutive filtering with logical indexing.\n\n# 2) Group genre_df by the 'genre' column, take one of its columns, \n#    and use the count() method to find the number of entries for each of \n#    the represented genres; store the resulting Series to the\n#    genre_df_count variable\n\n# 3) Sort genre_df_count in descending order of frequency and store the result\n#    to the genre_df_sorted variable\n\n# 4) Return a Series object with the first 15 genre_df_sorted value - the 15 most\n#    popular genres (on a given day, within a certain timeframe)\n\ndef genre_weekday(df, day, time1, time2):\n    # consecutive filtering\n    # genre_df will store only those df rows where the day is equal to day=\n    genre_df = df[df['day'] == day]\n    # genre_df will store only those df rows where the time is smaller than time2=\n    genre_df = genre_df[genre_df['time'] < time2]\n    # genre_df will store only those df rows where the time is greater than time1=\n    genre_df = genre_df[genre_df['time'] > time1]\n    # group the filtered DataFrame by the column with the names of genres, take the genre column, and find the number of rows for each genre with the count() method\n    genre_df_grouped = genre_df.groupby('genre')['genre'].count()\n    # we will sort the result in descending order (so that the most popular genres come first in the Series object)\n    genre_df_sorted = genre_df_grouped.sort_values(ascending=False)\n    # we will return the Series object storing the 15 most popular genres on a given day in a given timeframe\n    return genre_df_sorted[:15]"},{"cell_type":"markdown","metadata":{"id":"la2s2_PF_Zcu"},"source":"Compare the results of the `genre_weekday()` function for Springfield and Shelbyville on Monday morning (from 7AM to 11AM) and on Friday evening (from 17:00 to 23:00):"},{"cell_type":"code","execution_count":31,"metadata":{"id":"yz7itPUQ_Zcu","trusted":true},"outputs":[{"data":{"text/plain":"genre\npop            781\ndance          549\nelectronic     480\nrock           474\nhiphop         286\nruspop         186\nworld          181\nrusrap         175\nalternative    164\nunknown        161\nclassical      157\nmetal          120\njazz           100\nfolk            97\nsoundtrack      95\nName: genre, dtype: int64"},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":"# calling the function for Monday morning in Springfield (use spr_general instead of the df table)\n\ngenre_weekday(spr_general, 'Monday', '07:00', '11:00')"},{"cell_type":"code","execution_count":32,"metadata":{"id":"kwUcHPdy_Zcu","trusted":true},"outputs":[{"data":{"text/plain":"genre\npop            218\ndance          182\nrock           162\nelectronic     147\nhiphop          80\nruspop          64\nalternative     58\nrusrap          55\njazz            44\nclassical       40\nworld           36\nrap             32\nsoundtrack      31\nmetal           27\nrnb             27\nName: genre, dtype: int64"},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":"# calling the function for Monday morning in Shelbyville (use shel_general instead of the df table)\n\ngenre_weekday(shel_general, 'Monday', '07:00', '11:00')"},{"cell_type":"code","execution_count":33,"metadata":{"id":"EzXVRE1o_Zcu","trusted":true},"outputs":[{"data":{"text/plain":"genre\npop            713\nrock           517\ndance          495\nelectronic     482\nhiphop         273\nworld          208\nruspop         170\nclassical      163\nalternative    163\nrusrap         142\njazz           111\nunknown        110\nsoundtrack     105\nrnb             90\nmetal           88\nName: genre, dtype: int64"},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":"# calling the function for Friday evening in Springfield\n\ngenre_weekday(spr_general, 'Friday', '17:00', '23:00')"},{"cell_type":"code","execution_count":34,"metadata":{"id":"JZaEKu5v_Zcu","trusted":true},"outputs":[{"data":{"text/plain":"genre\npop            256\nrock           216\nelectronic     216\ndance          210\nhiphop          97\nalternative     63\njazz            61\nclassical       60\nrusrap          59\nworld           54\nruspop          47\nunknown         47\nsoundtrack      40\nmetal           39\nrap             36\nName: genre, dtype: int64"},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":"# calling the function for Friday evening in Shelbyville\n\ngenre_weekday(shel_general, 'Friday', '17:00', '23:00')"},{"cell_type":"markdown","metadata":{"id":"wrCe4MNX_Zcu"},"source":"**Conclusion**\n\nHaving compared the top 15 genres on Monday morning, we can draw the following conclusions:\n\n1. Users from Springfield and Shelbyville listen to similar music. The top five genres are the same, only rock and electronic have switched places.\n\n2. In Springfield, the number of missing values turned out to be so big that the value `'unknown'` came in 10th. This means that missing values make up a considerable portion of the data, which may be a basis for questioning the reliability of our conclusions.\n\nFor Friday evening, the situation is similar. Individual genres vary somewhat, but on the whole, the top 15 is similar for the two cities.\n\nThus, the second hypothesis has been partially proven true:\n* Users listen to similar music at the beginning and end of the week.\n* There is no major difference between Springfield and Shelbyville. In both cities, pop is the most popular genre.\n\nHowever, the number of missing values makes this result questionable. In Springfield, there are so many that they affect our top 15. Were we not missing these values, things might look different."},{"cell_type":"markdown","metadata":{"id":"jLmXgdanVyhP"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"JolODAqr_Zcu"},"source":"### Hypothesis 3: genre preferences in Springfield and Shelbyville <a id='genre'></a>\n\nHypothesis: Shelbyville loves rap music. Springfield's citizens are more into pop."},{"cell_type":"markdown","metadata":{"id":"DlegSvaT_Zcu"},"source":"Group the `spr_general` table by genre and find the number of songs played for each genre with the `count()` method. Then sort the result in descending order and store it to `spr_genres`."},{"cell_type":"code","execution_count":35,"metadata":{"id":"r19lIPke_Zcu","trusted":true},"outputs":[],"source":"# on one line: group the spr_general table by the 'genre' column, \n# count the 'genre' values with count() in the grouping, \n# sort the resulting Series in descending order, and store it to spr_genres\nspr_genres = spr_general.groupby('genre')['genre'].count().sort_values(ascending=False)"},{"cell_type":"markdown","metadata":{"id":"6kMuomxTiIr8"},"source":"Print the first 10 rows from `spr_genres`:"},{"cell_type":"code","execution_count":36,"metadata":{"id":"WhCSooF8_Zcv","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"genre\npop            5892\ndance          4435\nrock           3965\nelectronic     3786\nhiphop         2096\nclassical      1616\nworld          1432\nalternative    1379\nruspop         1372\nrusrap         1161\nName: genre, dtype: int64\n"}],"source":"# printing the first 10 rows of spr_genres\nprint(spr_genres.head(10))"},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nOne more trick is to convert series to a dataframe:</div>"},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre</th>\n    </tr>\n    <tr>\n      <th>genre</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>pop</td>\n      <td>5892</td>\n    </tr>\n    <tr>\n      <td>dance</td>\n      <td>4435</td>\n    </tr>\n    <tr>\n      <td>rock</td>\n      <td>3965</td>\n    </tr>\n    <tr>\n      <td>electronic</td>\n      <td>3786</td>\n    </tr>\n    <tr>\n      <td>hiphop</td>\n      <td>2096</td>\n    </tr>\n    <tr>\n      <td>classical</td>\n      <td>1616</td>\n    </tr>\n    <tr>\n      <td>world</td>\n      <td>1432</td>\n    </tr>\n    <tr>\n      <td>alternative</td>\n      <td>1379</td>\n    </tr>\n    <tr>\n      <td>ruspop</td>\n      <td>1372</td>\n    </tr>\n    <tr>\n      <td>rusrap</td>\n      <td>1161</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             genre\ngenre             \npop           5892\ndance         4435\nrock          3965\nelectronic    3786\nhiphop        2096\nclassical     1616\nworld         1432\nalternative   1379\nruspop        1372\nrusrap        1161"},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":"# Reviewer's code\n\nspr_genres.to_frame().head(10)"},{"cell_type":"markdown","metadata":{"id":"cnPG2vnN_Zcv"},"source":"Now do the same with the data on Shelbyville.\n\nGroup the `shel_general` table by genre and find the number of songs played for each genre. Then sort the result in descending order and store it to the `shel_genres` table:\n"},{"cell_type":"code","execution_count":37,"metadata":{"id":"gluLIpE7_Zcv","trusted":true},"outputs":[],"source":"# on one line: group the shel_general table by the 'genre' column, \n# count the 'genre' values in the grouping with count(), \n# sort the resulting Series in descending order and store it to shel_genres\nshel_genres = shel_general.groupby('genre')['genre'].count().sort_values(ascending=False)"},{"cell_type":"markdown","metadata":{"id":"5Doha_ODgyQ8"},"source":"Print the first 10 rows of `shel_genres`:"},{"cell_type":"code","execution_count":38,"metadata":{"id":"uaGJHjVU_Zcv","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"genre\npop            2431\ndance          1932\nrock           1879\nelectronic     1736\nhiphop          960\nalternative     649\nclassical       646\nrusrap          564\nruspop          538\nworld           515\nName: genre, dtype: int64\n"}],"source":"# printing the first 10 rows from shel_genres\nprint(shel_genres.head(10))"},{"cell_type":"markdown","metadata":{"id":"RY51YJYu_Zcv"},"source":"**Conclusion**"},{"cell_type":"markdown","metadata":{"id":"nVhnJEm__Zcv"},"source":"The hypothesis has been partially proven true:\n* Pop music is the most popular genre in Springfield, as expected.\n* However, pop music turned out to be equally popular in Springfield and Shelbyville, and rap wasn't in the top 5 for either city.\n"},{"cell_type":"markdown","metadata":{"id":"Byr0RfpPVz14"},"source":"[Back to Contents](#back)"},{"cell_type":"markdown","metadata":{"id":"ykKQ0N65_Zcv"},"source":"# Findings <a id='end'></a>"},{"cell_type":"markdown","metadata":{"id":"tjUwbHb3_Zcv"},"source":"We have tested the following three hypotheses:\n\n1. User activity differs depending on the day of the week and from city to city. \n2. On Monday mornings, Springfield and Shelbyville residents listen to different genres. This is also true for Friday evenings. \n3. Springfield and Shelbyville listeners have different preferences. In both Springfield and Shelbyville, they prefer pop.\n\nAfter analyzing the data, we concluded:\n\n1. User activity in Springfield and Shelbyville depends on the day of the week, though the cities vary in different ways. \n\nThe first hypothesis is fully accepted.\n\n2. Musical preferences do not vary significantly over the course of the week in both Springfield and Shelbyville. We can see small differences in order on Mondays, but:\n* In Springfield and Shelbyville, people listen to pop music most.\n\nSo we can't accept this hypothesis. We must also keep in mind that the result could have been different if not for the missing values.\n\n3. It turns out that the musical preferences of users from Springfield and Shelbyville are quite similar.\n\nThe third hypothesis is rejected. If there is any difference in preferences, it cannot be seen from this data.\n\n### Note \nIn real projects, research involves statistical hypothesis testing, which is more precise and more quantitative. Also note that you cannot always draw conclusions about an entire city based on the data from just one source.\n\nYou will study hypothesis testing in the sprint on statistical data analysis."},{"cell_type":"markdown","metadata":{},"source":"<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n<h2> Reviewer's comment</h2>\n    \nThe general conclusion is very important. Often, our tasks end with the  presentation or report for the client. Therefore, all results should be described in a general conclusion. Ideally, one should reinforce it with the previously obtained values.\n</div>"},{"cell_type":"markdown","metadata":{},"source":"<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n<h2> Overall conclusion <a class=\"tocSkip\"></h2>\n \n    \nThank you for submitting your project. You've done a really good job! Groupby methods are used correctly, functions are written accurately, all the results are correct. I see that you are already good at pandas 😊 \n    \nI've left a couple of recommendations for improving the project. I have no questions and there are no issues that need to be fixed, so I can accept the project now. However, I will send it back to you so that you have the opportunity to ask me questions, if you have any.    \n    \n  \n<hr>    \nBest regards,\n    \nSveta    \n    \n</div>"},{"cell_type":"markdown","metadata":{"id":"Ju4AHDSgV1FE"},"source":"[Back to Contents](#back)"}],"metadata":{"ExecuteTimeLog":[{"duration":921,"start_time":"2021-10-31T10:20:45.518Z"},{"duration":186,"start_time":"2021-10-31T10:20:49.110Z"},{"duration":196,"start_time":"2021-10-31T10:20:54.336Z"},{"duration":193,"start_time":"2021-10-31T10:20:57.054Z"},{"duration":192,"start_time":"2021-10-31T10:21:04.629Z"},{"duration":195,"start_time":"2021-10-31T10:21:06.724Z"},{"duration":197,"start_time":"2021-10-31T10:22:57.724Z"},{"duration":10,"start_time":"2021-10-31T10:23:29.844Z"},{"duration":11,"start_time":"2021-10-31T10:24:27.839Z"},{"duration":31,"start_time":"2021-10-31T10:24:31.246Z"},{"duration":6,"start_time":"2021-10-31T10:59:47.060Z"},{"duration":18,"start_time":"2021-10-31T11:06:49.252Z"},{"duration":5,"start_time":"2021-10-31T11:06:51.314Z"},{"duration":30,"start_time":"2021-10-31T11:08:16.235Z"},{"duration":33,"start_time":"2021-10-31T11:09:33.304Z"},{"duration":55,"start_time":"2021-10-31T11:09:38.565Z"},{"duration":56,"start_time":"2021-10-31T11:10:24.920Z"},{"duration":31,"start_time":"2021-10-31T11:15:02.889Z"},{"duration":52,"start_time":"2021-10-31T11:15:24.266Z"},{"duration":24,"start_time":"2021-10-31T11:15:30.210Z"},{"duration":31,"start_time":"2021-10-31T11:15:31.313Z"},{"duration":369,"start_time":"2021-10-31T11:16:52.296Z"},{"duration":80,"start_time":"2021-10-31T11:17:36.750Z"},{"duration":88,"start_time":"2021-10-31T11:18:26.909Z"},{"duration":76,"start_time":"2021-10-31T11:18:33.817Z"},{"duration":98,"start_time":"2021-10-31T11:21:27.044Z"},{"duration":76,"start_time":"2021-10-31T11:21:31.161Z"},{"duration":7,"start_time":"2021-10-31T11:24:05.930Z"},{"duration":8,"start_time":"2021-10-31T11:24:14.602Z"},{"duration":9,"start_time":"2021-10-31T11:24:44.910Z"},{"duration":7,"start_time":"2021-10-31T11:25:36.747Z"},{"duration":8,"start_time":"2021-10-31T11:25:45.237Z"},{"duration":98,"start_time":"2021-10-31T11:26:50.344Z"},{"duration":279,"start_time":"2021-10-31T11:26:54.392Z"},{"duration":355,"start_time":"2021-10-31T11:27:32.342Z"},{"duration":80,"start_time":"2021-10-31T11:28:08.927Z"},{"duration":114,"start_time":"2021-10-31T11:28:53.047Z"},{"duration":78,"start_time":"2021-10-31T11:29:18.335Z"},{"duration":74,"start_time":"2021-10-31T11:31:53.242Z"},{"duration":279,"start_time":"2021-10-31T12:00:07.314Z"},{"duration":4,"start_time":"2021-10-31T12:00:10.476Z"},{"duration":13,"start_time":"2021-10-31T12:00:11.413Z"},{"duration":3,"start_time":"2021-10-31T12:00:26.450Z"},{"duration":76,"start_time":"2021-10-31T12:00:29.100Z"},{"duration":43,"start_time":"2021-10-31T12:06:04.856Z"},{"duration":42,"start_time":"2021-10-31T12:07:58.016Z"},{"duration":276,"start_time":"2021-10-31T12:17:40.350Z"},{"duration":287,"start_time":"2021-10-31T12:17:48.478Z"},{"duration":4,"start_time":"2021-10-31T12:18:00.587Z"},{"duration":21,"start_time":"2021-10-31T12:18:46.864Z"},{"duration":27,"start_time":"2021-10-31T12:19:15.508Z"},{"duration":20,"start_time":"2021-10-31T12:19:16.807Z"},{"duration":24,"start_time":"2021-10-31T12:20:06.129Z"},{"duration":20,"start_time":"2021-10-31T12:20:12.380Z"},{"duration":28,"start_time":"2021-10-31T12:20:18.311Z"},{"duration":21,"start_time":"2021-10-31T12:20:19.909Z"},{"duration":5,"start_time":"2021-10-31T12:22:26.843Z"},{"duration":4,"start_time":"2021-10-31T12:22:48.633Z"},{"duration":20,"start_time":"2021-10-31T12:22:49.931Z"},{"duration":17,"start_time":"2021-10-31T12:22:52.831Z"},{"duration":18,"start_time":"2021-10-31T12:22:54.078Z"},{"duration":18,"start_time":"2021-10-31T12:22:54.884Z"},{"duration":21,"start_time":"2021-10-31T12:22:55.665Z"},{"duration":18,"start_time":"2021-10-31T12:22:56.374Z"},{"duration":20,"start_time":"2021-10-31T12:44:56.034Z"},{"duration":20,"start_time":"2021-10-31T12:45:08.064Z"},{"duration":4,"start_time":"2021-10-31T12:45:10.348Z"},{"duration":21,"start_time":"2021-10-31T12:45:11.089Z"},{"duration":19,"start_time":"2021-10-31T12:45:17.049Z"},{"duration":18,"start_time":"2021-10-31T12:45:23.267Z"},{"duration":18,"start_time":"2021-10-31T12:46:12.407Z"},{"duration":20,"start_time":"2021-10-31T12:46:21.797Z"},{"duration":19,"start_time":"2021-10-31T12:46:55.149Z"},{"duration":4,"start_time":"2021-10-31T12:46:57.637Z"},{"duration":19,"start_time":"2021-10-31T12:46:58.571Z"},{"duration":20,"start_time":"2021-10-31T12:47:04.753Z"},{"duration":17,"start_time":"2021-10-31T12:47:49.375Z"},{"duration":17,"start_time":"2021-10-31T12:47:55.739Z"},{"duration":19,"start_time":"2021-10-31T12:47:58.441Z"},{"duration":19,"start_time":"2021-10-31T12:48:03.861Z"},{"duration":17,"start_time":"2021-10-31T12:48:08.999Z"},{"duration":4,"start_time":"2021-10-31T12:52:21.329Z"},{"duration":13,"start_time":"2021-10-31T12:53:36.313Z"},{"duration":20,"start_time":"2021-10-31T12:53:56.513Z"},{"duration":17,"start_time":"2021-10-31T12:53:56.916Z"},{"duration":18,"start_time":"2021-10-31T12:53:57.328Z"},{"duration":17,"start_time":"2021-10-31T12:53:57.748Z"},{"duration":21,"start_time":"2021-10-31T12:53:58.216Z"},{"duration":17,"start_time":"2021-10-31T12:53:58.699Z"},{"duration":12,"start_time":"2021-10-31T12:54:00.651Z"},{"duration":14,"start_time":"2021-10-31T13:05:33.666Z"},{"duration":14,"start_time":"2021-10-31T13:05:36.560Z"},{"duration":6,"start_time":"2021-10-31T13:09:45.716Z"},{"duration":23,"start_time":"2021-10-31T13:10:04.391Z"},{"duration":17,"start_time":"2021-10-31T13:10:07.005Z"},{"duration":24,"start_time":"2021-10-31T13:10:13.324Z"},{"duration":17,"start_time":"2021-10-31T13:10:15.873Z"},{"duration":42,"start_time":"2021-10-31T13:13:57.985Z"},{"duration":16,"start_time":"2021-10-31T13:16:45.701Z"},{"duration":12,"start_time":"2021-10-31T13:17:13.179Z"},{"duration":5,"start_time":"2021-10-31T13:17:23.025Z"},{"duration":285,"start_time":"2021-10-31T13:18:09.574Z"},{"duration":9,"start_time":"2021-10-31T13:18:11.124Z"},{"duration":6,"start_time":"2021-10-31T13:18:12.531Z"},{"duration":191,"start_time":"2021-10-31T13:19:19.941Z"},{"duration":215,"start_time":"2021-10-31T13:19:20.134Z"},{"duration":19,"start_time":"2021-10-31T13:19:20.352Z"},{"duration":35,"start_time":"2021-10-31T13:19:20.373Z"},{"duration":4,"start_time":"2021-10-31T13:19:20.411Z"},{"duration":52,"start_time":"2021-10-31T13:19:20.418Z"},{"duration":4,"start_time":"2021-10-31T13:19:20.474Z"},{"duration":57,"start_time":"2021-10-31T13:19:20.482Z"},{"duration":48,"start_time":"2021-10-31T13:19:20.541Z"},{"duration":29,"start_time":"2021-10-31T13:19:20.592Z"},{"duration":109,"start_time":"2021-10-31T13:19:20.623Z"},{"duration":111,"start_time":"2021-10-31T13:19:20.734Z"},{"duration":80,"start_time":"2021-10-31T13:19:20.847Z"},{"duration":90,"start_time":"2021-10-31T13:19:20.929Z"},{"duration":4,"start_time":"2021-10-31T13:19:21.022Z"},{"duration":17,"start_time":"2021-10-31T13:19:21.028Z"},{"duration":98,"start_time":"2021-10-31T13:19:21.047Z"},{"duration":49,"start_time":"2021-10-31T13:19:21.147Z"},{"duration":41,"start_time":"2021-10-31T13:19:21.201Z"},{"duration":23,"start_time":"2021-10-31T13:19:21.245Z"},{"duration":23,"start_time":"2021-10-31T13:19:21.270Z"},{"duration":17,"start_time":"2021-10-31T13:19:21.295Z"},{"duration":54,"start_time":"2021-10-31T13:19:21.314Z"},{"duration":17,"start_time":"2021-10-31T13:19:21.370Z"},{"duration":19,"start_time":"2021-10-31T13:19:21.390Z"},{"duration":17,"start_time":"2021-10-31T13:19:21.411Z"},{"duration":44,"start_time":"2021-10-31T13:19:21.430Z"},{"duration":18,"start_time":"2021-10-31T13:19:21.477Z"},{"duration":14,"start_time":"2021-10-31T13:19:21.497Z"},{"duration":6,"start_time":"2021-10-31T13:19:21.514Z"},{"duration":60,"start_time":"2021-10-31T13:19:21.522Z"},{"duration":18,"start_time":"2021-10-31T13:19:21.585Z"},{"duration":27,"start_time":"2021-10-31T13:19:21.606Z"},{"duration":17,"start_time":"2021-10-31T13:19:21.668Z"},{"duration":13,"start_time":"2021-10-31T13:19:21.687Z"},{"duration":8,"start_time":"2021-10-31T13:19:21.702Z"},{"duration":11,"start_time":"2021-10-31T13:19:21.713Z"},{"duration":45,"start_time":"2021-10-31T13:19:21.726Z"},{"duration":737,"start_time":"2021-10-31T19:15:46.182Z"},{"duration":133,"start_time":"2021-10-31T19:15:46.921Z"},{"duration":6,"start_time":"2021-10-31T19:15:47.056Z"},{"duration":27,"start_time":"2021-10-31T19:15:47.064Z"},{"duration":15,"start_time":"2021-10-31T19:15:47.093Z"},{"duration":34,"start_time":"2021-10-31T19:15:47.110Z"},{"duration":4,"start_time":"2021-10-31T19:15:47.146Z"},{"duration":63,"start_time":"2021-10-31T19:15:47.152Z"},{"duration":15,"start_time":"2021-10-31T19:15:47.219Z"},{"duration":28,"start_time":"2021-10-31T19:15:47.237Z"},{"duration":55,"start_time":"2021-10-31T19:15:47.267Z"},{"duration":72,"start_time":"2021-10-31T19:15:47.324Z"},{"duration":49,"start_time":"2021-10-31T19:15:47.397Z"},{"duration":46,"start_time":"2021-10-31T19:15:47.447Z"},{"duration":3,"start_time":"2021-10-31T19:15:47.494Z"},{"duration":13,"start_time":"2021-10-31T19:15:47.498Z"},{"duration":62,"start_time":"2021-10-31T19:15:47.513Z"},{"duration":29,"start_time":"2021-10-31T19:15:47.576Z"},{"duration":45,"start_time":"2021-10-31T19:15:47.606Z"},{"duration":3,"start_time":"2021-10-31T19:15:47.653Z"},{"duration":33,"start_time":"2021-10-31T19:15:47.657Z"},{"duration":19,"start_time":"2021-10-31T19:15:47.692Z"},{"duration":25,"start_time":"2021-10-31T19:15:47.713Z"},{"duration":14,"start_time":"2021-10-31T19:15:47.739Z"},{"duration":21,"start_time":"2021-10-31T19:15:47.754Z"},{"duration":14,"start_time":"2021-10-31T19:15:47.777Z"},{"duration":57,"start_time":"2021-10-31T19:15:47.795Z"},{"duration":48,"start_time":"2021-10-31T19:15:47.853Z"},{"duration":9,"start_time":"2021-10-31T19:15:47.903Z"},{"duration":11,"start_time":"2021-10-31T19:15:47.913Z"},{"duration":21,"start_time":"2021-10-31T19:15:47.926Z"},{"duration":11,"start_time":"2021-10-31T19:15:47.949Z"},{"duration":20,"start_time":"2021-10-31T19:15:47.961Z"},{"duration":13,"start_time":"2021-10-31T19:15:47.982Z"},{"duration":10,"start_time":"2021-10-31T19:15:47.996Z"},{"duration":4,"start_time":"2021-10-31T19:15:48.007Z"},{"duration":35,"start_time":"2021-10-31T19:15:48.013Z"},{"duration":10,"start_time":"2021-10-31T19:15:48.049Z"},{"duration":11,"start_time":"2021-10-31T19:18:52.252Z"},{"duration":13,"start_time":"2021-10-31T19:19:06.060Z"},{"duration":7,"start_time":"2021-10-31T19:20:20.736Z"}],"colab":{"collapsed_sections":["E0vqbgi9ay0H","VUC88oWjTJw2","atZAxtq4_Zcu"],"name":"EmptyFinalProject.ipynb\"","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}